\documentclass[annual]{acmsiggraph}
\usepackage[utf8]{inputenc}

\TOGonlineid{45678}
\TOGvolume{0}
\TOGnumber{0}
\TOGarticleDOI{1111111.2222222}
\TOGprojectURL{}
\TOGvideoURL{}
\TOGdataURL{}
\TOGcodeURL{}

\title{Error Analysis of Precomputed Radiance Transfer for Deforming
Geometry}

\author{João L. Cardoso \thanks{McGill University} \space \thanks{University of Coimbra} \and Paul G. Kry \footnotemark[1]}
\pdfauthor{João L. Cardoso}

\keywords{radiance transfer, radiosity, global illumination, lambertian surfaces, principal component analysis}

\begin{document}
\teaser{
  \includegraphics[width=7in]{images/ambients.png}
  \caption{Ambient light can be changed in real-time as the animation is rendered.}
}

\maketitle

\begin{abstract}

In this project we explore the approximation errors associated with precomputed light transport techniques on lambertian surfaces.

Low frequency lighting is described on a spherical harmonic basis. Transfer functions for direct lighting components are computed for every pose on each vertex of the model. The resulting animation is then approximated to a smaller data set with less memory requirements using a principal component analysis of both the geometry and transfer functions across the set of poses.

At run-time, the geometry and transfer functions are reconstructed as necessary from the resulting singular value decomposition, and an environment light applied to the transfer functions. An analysis of the theoretical and visual errors due to the reconstruction and spherical harmonic approximations is then performed.

\end{abstract}

\keywordlist
\copyrightspace

\section{Introduction}

Although the underlying principles of lighting are well understood, their efficient computation is still a challenging problem. Many features - such as diffuse and glossy shading, lighting from area sources, soft shadows, indirect illumination, caustics, subsurface scattering and interreflections - are so computationally expensive that they can take minutes or hours to compute on average complexity scenes \shortcite{pbrt,state}, making the general approaches unusable for real-time rendering.

Commonly, this is solved by resorting to precomputation based techniques, such as precomputed radiance transfer. This category of methods traditionally constraint the scene geometry to be rigid and, under this assumption, the surface reflection proprieties of the model can be computed, allowing for real-time rendering of features such as self-shadowing and self-interreflection on \textbf{any} lighting environment (figure 1) \shortcite{sloan,state}.

Yet, this constraint greatly restricts the practical application of these techniques. For that reason, a number of techniques have been proposed over the past years, that cope precomputed radiance transfer techniques with animated geometry. \cite{zonal} proposed the use of zonal harmonics, which works particularly well for effects such as bumps or other details. \cite{impulses} proposed the use of impulse response functions, which allow for physical interaction with the models under certain constraints. Our approach resembles more the work developed by \cite{deformable}, which resorts to a singular value analysis of the transfer functions computed for each possible poses. 

\section{Radiance Transfer}

On a more physically based rendering pipeline, geometry is commonly lighted by computing the resulting color on some points on the model, and the remaining area by interpolation of these points. Precomputed radiance transfer techniques, on the other hand, turn this idea upside down, and compute the surface proprieties - how they reflect different types of light - on those points instead. Then, the ambient light can be approximated as a composition of these types and the color computed.

A pertinent question is how should these points be chosen. A common approach is sampling them across the surface using Monte-Carlo techniques \shortcite{pbrt}. Yet, due to out interest in rendering a series of poses, we compute the transfer on each vertex, which ensures all rendered points match across the entire simulation.

Another important factor is the reflection model to be used. In this project we focus on lambertian surfaces, as this model defines that the brightness of a surface to an observer is the same regardless of the observer's angle of view. Yet, other models could have been used, as shown by \cite{glossy}, which extended this idea to support all frequency transfer using a factorization of bidirectional reflectance distribution functions.

\subsection{Spherical Harmonics}

One must also chose a representation for the transfer functions. In this project we encode them using spherical harmonic coefficients, as described by \cite{sloan}. On a strict definition, their functions define an orthonormal basis over the unit sphere, analogous to the Fourier transform over that domain. Yet, the mathematical definition and algorithms used for the coefficient computation are out of the scope of these project, and hence will not be covered on this report.

\begin{figure}[ht]
  \centering
  \includegraphics[width=3in]{images/harmonics.png}
  \caption{Visual representations of the first few spherical harmonics. Red portions represent regions where the function is positive, and green portions represent regions where the function is negative.}
\end{figure}

There is an infinite amount of spherical harmonic coefficients, ordered from low to high frequency basis functions over the sphere, and divided into a series of bands.
Theoretically, computing this infinite recurrence would give an exact representation of the transfer. Computing a finite number constitutes is thereby a valid approximation, as long as it corresponds to a number of bands.

\subsection{Reconstruction}
Let $l$ be the maximum band to be used. Then $n$, the number of coefficients, is:

\begin{equation}
	n = (l + 1)^2
\end{equation}

Suppose $T = [T_{0}, T_{1}, ..., T_{n}]$ is the precomputed radiance transfer vector of some point $p$ on a surface, and $A = [A_{0}, A_{1}, ..., A_{n}]$ the approximation of the ambient light on the SH basis. Then the color $c$ of the surface on $p$ is obtained as:

\begin{equation}
	c = T \cdot A
\end{equation}

\begin{figure}[ht]
  \centering
  \includegraphics[width=3.3in]{images/octopusSH.png}
  \caption{The first four spherical harmonic coefficients, from top-left to bottom-right, as viewed using our renderer. Blue represents regions where the coefficient is positive, and red where is negative.}
\end{figure}

Gouraud shading is then used to interpolate the resulting colors on the vertices across the surface of the model.

\section{Storage}

The major drawback of precomputed radiance transfer on animated geometry - besides precomputation time - is the memory requirements. While precomputing the transfer for every pose is not much of an issue, storing and loading it into memory is impractical on current hardware.

For instance, the octopus is constituted by about $104000$ vertices and $100$ poses. Precomputing and storing the spheric harmonic coefficients for every pose using $3$ bands would thereby require $104000 * 100 * 9 * 3 = 280800000$ floating point values just to represent the transfer functions the three RGB components. While this is not too large to fit in random access memory of the contemporary common computer, it is still too high to be used in practical situations.

Instead, we approximate separately the geometry and SH coefficients to a smaller data set.

\subsection{Singular Value Decompostion}

Principal component analysis is used to obtain a basis for a data set such that variation of the data is maximized along the coordinate axes. Data reduction is achieved by ignoring the axes of lowest variation, thereby projecting the original data into a lower dimensional space with minimal loss of accuracy. On a loose sense, this can be seen as redefining the animation as a smaller set of features, which can be interpolated to reconstruct the original animation.

\begin{figure}[ht]
  \centering
  \includegraphics[width=3in]{images/clusters.png}
  \caption{Variation of the data is greatest along the newly defined axes than on the canonical ones. $y'$ could be ignored to perform a data reduction, thus projecting it into a 1D data set.}
\end{figure}

To make use of this algorithm, we first define two new matrixes - one for the geometry and another for the transfer. The operations performed on both are the same, and hence we will reference an abstract matrix $A$ from this point forward.

Let $P_{i}$ be a vector containing the data relative to the ith pose of the model. Let $A_{m \times n}$ be our new matrix, where $m$ is the size of $P_{i}$ and $n$ the number of poses. Then $A$ is defined as:
\begin{equation}
	A = \begin{bmatrix}
		P_{0}^{T} & \cdots & P_{n}^{T} \\
	\end{bmatrix}
\end{equation}

For example, the $A$ matrix for the geometry has the following representation:
\begin{equation}
	A_{geometry} = \begin{pmatrix}
		x & \cdots & x \\
		y & \cdots & y \\
		z & \cdots & z \\
		\vdots & \ddots & \vdots \\
		x & \cdots & x \\
		y & \cdots & y \\
		z & \cdots & z \\
	\end{pmatrix}
\end{equation}

Factorizing $A$ directly is not very efficient, as that would make the most important features of the data set to be it's average. Hence, we first calculate the mean of every row, $M$, and subtract it from $A$, so that every value is the distance from the mean:

\begin{equation}
	M_{i} = \sum _{k = 0} ^{n} \frac {A_{i,k}} {n}
\end{equation}

\begin{equation}
	A'_{\text{row i}} = A_{\text{row i}} - M_{i}
\end{equation}

We then perform the singular value decomposition:
\begin{equation}
	A'_{m \times n} = U_{m \times n} \cdot S_{n \times n} \cdot V _{n \times n}
\end{equation}

where $U$ and $V^{T}$ are two unitary matrixes and $S$ ia diagonal matrix whose entries contain the singular values of $A'$. These values indicate the variation of the corresponding basis and are ordered in decreasing magnitude. One might thus discard the $n - t$ lower variation axes, where $t$ is an integer, by performing a truncation of the three matrixes.

\begin{equation}
	A'_{m \times t} = U_{m \times t} \cdot S_{t \times t} \cdot V _{t \times t}
\end{equation}

\subsection{Reconstruction}

While one could reconstruct the entire matrix $A'$, that would defeat the entire purpose of the decomposition. Instead, we will reconstruct and store in memory one pose at the time:

\begin{equation}
	P_{i} \simeq M + U \cdot S \cdot V_{\text{column } i}
\end{equation}

Furthermore, $S$ and $V$ are square matrixes of the same size, and thus can be premultiplied before rendering:

\begin{equation}
	V' = S \cdot V
\end{equation}
\begin{equation}
	P_{i} \simeq M + U \cdot V'_{\text{column } i}
\end{equation}

\section{Error Analysis}

Regarding the singular value decompositions of the geometry and transfer coefficients, both theoretical and visual relative errors were computed. The first is the expected error that, given a set of singular values, would come from truncating $S$. It is computed has:

\begin{equation}
	E_{theoretical} = \frac {\sum _{i = t+1} ^{n} S_{i,i}} {\sum _{i = 0} ^{n} S_{i,i}}
\end{equation}

where $t$ is the number of components retained. Visual errors are computed by simple comparison of the resulting images, pixel by pixel. Let $I_{f}$ be the resulting image using all components or bands, and $I_{p}$ using a specified number:

\begin{equation}
	E_{visual} = \frac {|I_{f} - I_{p}|} {|I_{f}|}
\end{equation}

Using the above formulas, the results obtained for the octopus model are presented in the table below:

\begin{tabular}{ |l|c|c|c|c|c| }
  \hline
  Geometry Components & 103 & 20 & 7 & 4 & 2 \\
  \hline
  Theoretical Error & 0\% & 0.58\% & 2.23\% & 4.68\% & 8.3\% \\
  Visual Error & 0\% & 2.83\% & 4.41\% & 5.37\% & 6\% \\
  \hline
\end{tabular}

\begin{tabular}{ |l|c|c|c|c|c| }
  \hline
  Transfer Components & 103 & 20 & 7 & 4 & 2 \\
  \hline
  Theoretical Error & 0\% & 7.67\% & 15.56\% & 20.24\% & 25.5\% \\
  Visual Error & 0\% & 0.64\% & 1.2\% & 1.75\% & 2.22\% \\
  \hline
\end{tabular}

\begin{tabular}{ |l|c|c|c| }
  \hline
  Spherical Bands & 7 & 4 & 2 \\
  \hline
  Visual Error & 0\%$^{*}$ & 0.5\% & 1.6\% \\
  \hline
\end{tabular}

As we can see, the expected error was smaller than the perceptible one for the geometry. On the other hand, the visible error when reducing the transfer dimensional space is much smaller than what expected. This fits the common sense reasoning that one is much more likely to notice an object is out of place, than its color is slightly off. It is also very favorable to our needs, as the transfer matrix tends to be much larger than the geometry: each vertex is represented with three floats for the geometry, but three are also required for each transfer coefficient.

We have assumed the results obtained from using seven spherical bands to be the ground truth. This is obviously not correct, but it is close enough to provide us a good approximation regarding the visual errors when reducing the number of bands.

\section{Implementation}

The implementation of the project required the development and extension of a number of independent applications.

\subsection{Pbrt}
For the transport precomputation, we have used a modified version of \emph{pbrt2} \shortcite{pbrt}, an open source implementation of a physically based renderer, as described in the second edition of the book. Although the renderer supports the computation of transport for direct lighting, the user is given no control on how these should be computed, nor the ability to perform operations on such values - they are only used for rendering images. So it had to be extended with new rendering modes to:

\begin{itemize}
	\item Compute the direct radiance transfer functions on specified point/normal pairs of a scene into a readable file.
	\item Approximate an ambient map on a spherical harmonic basis into a new file.
\end{itemize}

Other minor changes were made, such as adding the ability to automatically render several scenes in sequence -  vital for computing several poses.

\subsection{Obj Models}
\begin{figure}[t!]
  \centering
  \includegraphics[width=3.3in]{images/obj.png}
  \caption{(top) the normal of each vertex of the octahedron is computed as an average of all the vertex normals in the faces; (bottom) the obj renderer was constructed with the purpose of analyzing a model geometry and normals in mind.}
\end{figure}

The poses we wanted to use were stored in the \emph{obj} format, and thus an \emph{obj} loader was developed. Let $F_{v}$ be the faces a vertex $v$ belongs to, and $N(v, f$) the normal of a vertex on a given face. For the purposes of transport precomputation, the loader computes $n$, the normal of $v$ as:

\begin{equation}
	n = \frac {\sum _{f \in F_{v}}^{} N(v, f)} {|n|}
\end{equation}

Using the loader, an application was made to export the poses as \emph{pbrt} scenes, so that the transfer functions could be computed. For debugging purposes, an \emph{obj} renderer was also created.

Additionally, a small script that automatically adds common geometry (e.g: a floor) to a set of poses was created to modify our models.

\subsection{Paim Format}
After \emph{pbrt}'s precomputation has taken place, another exporter reads the poses and transfer files, and groups the information as the geometry and a transfer matrixes. It then performs the singular value decomposition as explained in section 3.1, for which we have used \emph{EJML}, a java matrix library. The results are stored in a binary format file, which was labeled \emph{paim} (pre-animated and illuminated model).

\begin{figure}[p]
  \centering
  \includegraphics[width=7in]{images/renderer.png}
  \parbox{7in} {
  \caption{our \emph{paim} model renderer, displaying an octopus model on a street environment light. Exposure is reduced for a clear visualization of self-occlusion.}}
\end{figure}

Just as for the \emph{obj} files, a \emph{paim} renderer was created. Using this application one might dynamically set the number of geometry and transfer components and spherical harmonics bands to be used. The model can then be viewed on any environment light, and controls for both exposure and gamma are provided. Alternatively, each spheric harmonic coefficient can be visualized as a red and blue color palette over the surface (figure 3).

The error analysis was performed using Matlab. For the purpose of computing visual errors, the renderer also supports taking a snapshot of the color buffer and storing into a readable text file for comparison.

\section{Acknowledgements}

We would like to thank Derek Nowrouzezahrai for his guidance regarding methods for light precomputation.

\bibliographystyle{acmsiggraph}
\bibliography{report}
\end{document}